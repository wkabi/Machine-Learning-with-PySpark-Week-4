{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 25\n\n# Convert categorical strings to index values\nindexer = StringIndexer(inputCol='org',outputCol='org_idx')\n\n# One-hot encode index values\nonehot = OneHotEncoderEstimator(\n    inputCols=['org_idx','dow'],\n    outputCols=['org_dummy','dow_dummy']\n)\n\n# Assemble predictors into a single column\nassembler = VectorAssembler(inputCols=['km','org_dummy','dow_dummy'], outputCol='features')\n\n# A linear regression object\nregression = LinearRegression(labelCol='duration')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 26\n\n# Import class for creating a pipeline\nfrom pyspark.ml import Pipeline\n\n# Construct a pipeline\npipeline = Pipeline(stages=[indexer,onehot,assembler,regression])\n\n# Train the pipeline on the training data\npipeline = pipeline.fit(flights_train)\n\n# Make predictions on the testing data\npredictions = pipeline.transform(flights_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 27\n\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n\n# Break text into tokens at non-word characters\ntokenizer = Tokenizer(inputCol='text', outputCol='words')\n\n# Remove stop words\nremover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='terms')\n\n# Apply the hashing trick and transform to TF-IDF\nhasher = HashingTF(inputCol=remover.getOutputCol(), outputCol=\"hash\")\nidf = IDF(inputCol=hasher.getOutputCol(), outputCol=\"features\")\n\n# Create a logistic regression object and add everything to a pipeline\nlogistic = LogisticRegression()\npipeline = Pipeline(stages=[tokenizer, remover, hasher, idf, logistic])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 28\n\n# Create an empty parameter grid\nparams = ParamGridBuilder().build()\n\n# Create objects for building and evaluating a regression model\nregression = LinearRegression(labelCol='duration')\nevaluator = RegressionEvaluator(labelCol='duration')\n\n# Create a cross validator\ncv = CrossValidator(estimator=regression, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)\n\n# Train and test model on multiple folds of the training data\ncv = cv.fit(flights_train)\n\n# NOTE: Since cross-valdiation builds multiple models, the fit() method can take a little while to complete.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 29\n\n# Create an indexer for the org field\nindexer = ____(____, ____)\n\n# Create an one-hot encoder for the indexed org field\nonehot = ____(____, ____)\n\n# Assemble the km and one-hot encoded fields\nassembler = ____(____, ____)\n\n# Create a pipeline and cross-validator.\npipeline = ____(stages=[____, ____, ____, ____])\ncv = ____(estimator=____,\n          estimatorParamMaps=____\n          evaluator=____)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 30\n\n# Create parameter grid\nparams = ParamGridBuilder()\n\n# Add grids for two parameters\nparams = params.addGrid(regression.regParam, [0.01, 0.1, 1, 10]) \\\n               .addGrid(regression.elasticNetParam, [0, 0.5, 1])\n\n# Build the parameter grid\nparams = params.build()\nprint('Number of models to be tested: ', len(params))\n\n# Create cross-validator\ncv = CrossValidator(estimator=pipeline, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 31\n\n# Get the best model from cross validation\nbest_model = cv.____\n\n# Look at the stages in the best model\nprint(best_model.____)\n\n# Get the parameters for the LinearRegression object in the best model\nbest_model.____.extractParamMap()\n\n# Generate predictions on testing data using the best model then calculate RMSE\npredictions = ____.____(____)\n____.____(____)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 32\n\n# Create parameter grid\nparams = ParamGridBuilder()\n\n# Add grid for hashing trick parameters\nparams = params.addGrid(hasher.numFeatures, [1024, 4096, 16384]) \\\n               .addGrid(hasher.binary, [True, False])\n\n# Add grid for logistic regression parameters\nparams = params.addGrid(logistic.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n               .addGrid(logistic.elasticNetParam, [0.0, 0.5, 1.0])\n\n# Build parameter grid\nparams = params.build()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 33\n\n# Import the classes required\nfrom pyspark.ml.classification import DecisionTreeClassifier, GBTClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Create model objects and train on training data\ntree = DecisionTreeClassifier().fit(flights_train)\ngbt = GBTClassifier().fit(flights_train)\n\n# Compare AUC on testing data\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(tree.transform(flights_test))\nevaluator.evaluate(gbt.transform(flights_test))\n\n# Find the number of trees and the relative importance of features\nprint(gbt.trees)\nprint(gbt.featureImportances)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 34\n\n# Create a random forest classifier\nforest = RandomForestClassifier()\n\n# Create a parameter grid\nparams = ParamGridBuilder() \\\n            .addGrid(forest.featureSubsetStrategy, ['all', 'onethird', 'sqrt', 'log2']) \\\n            .addGrid(forest.maxDepth, [2, 5, 10]) \\\n            .build()\n\n# Create a binary classification evaluator\nevaluator = BinaryClassificationEvaluator()\n\n# Create a cross-validator\ncv = CrossValidator(estimator=forest, estimatorParamMaps=params, evaluator=evaluator, numFolds=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exercise 35\n\n# Average AUC for each parameter combination in grid\navg_auc = cv.____\n\n# Average AUC for the best model\nbest_model_auc =  ____(____)\n\n# What's the optimal parameter value?\nopt_max_depth = cv.____.explainParam(____)\nopt_feat_substrat = cv.____.____(____)\n\n# AUC for best model on testing data\nbest_auc = evaluator.____(____.____(____))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}